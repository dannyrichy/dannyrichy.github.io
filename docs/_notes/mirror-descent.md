---
layout: default
title: Mirror Descent
category: "In Too Deep (Learning)"
---
## Mirror Descent

Date: 26/11/2024

There are some hard-core maths background for convex optimization which I don't want to rehash off of these posts
- [Convex analysis part I](https://tlienart.github.io/posts/2018/09/23-convex-optimisation-1/){:target="_blank"}., [Convex analysis part II](https://tlienart.github.io/posts/2018/09/24-convex-optimisation-2/){:target="_blank"}., [Convex analysis part III](https://tlienart.github.io/posts/2018/10/09-convex-optimisation-3/){:target="_blank"}. It introduces notion of proper convex functions

#### Whazzat

    Mirror descent is a method for constrained optimization


---
### References
- [T. Lienart's notes](https://tlienart.github.io/posts/){:target="_blank"}
- [Boyd's Lecture notes](https://see.stanford.edu/materials/lsocoee364b/01-subgradients_notes.pdf){:target="_blank"}
- [https://en.wikipedia.org/wiki/Mirror_descent](https://en.wikipedia.org/wiki/Mirror_descent){:target="_blank"}